# Day 3 Teacher's Guide
## Evening 3: The New Rules of Software Delivery

**Course:** AI for Software Managers Workshop  
**Session Date:** January 22, 2026  
**Location:** Digital Campus Vorarlberg  
**Instructor:** Frank Blau  
**Duration:** Evening Session (3-4 hours recommended)

---

## Table of Contents
1. [Pre-Class Setup Instructions](#pre-class-setup-instructions)
2. [Learning Objectives](#learning-objectives)
3. [Tool and Software Requirements](#tool-and-software-requirements)
4. [Daily Schedule](#daily-schedule)
5. [Detailed Topic Guide](#detailed-topic-guide)
6. [Activities and Exercises](#activities-and-exercises)
7. [Assignments](#assignments)
8. [Assessment and Evaluation](#assessment-and-evaluation)
9. [Teaching Resources](#teaching-resources)

---

## Pre-Class Setup Instructions

### 48 Hours Before Class

**Instructor Preparation:**
- [ ] Review Day 1 and Day 2 homework submissions
- [ ] Identify patterns in organizational readiness and governance needs
- [ ] Prepare real case studies of governance failures and successes
- [ ] Gather examples of effective quality gates from different organizations
- [ ] Compile vendor evaluation examples (at least 2)
- [ ] Prepare security risk scenarios for case study discussion
- [ ] Create template for 18-month roadmap with realistic examples

**Materials Preparation:**
- [ ] Print one "Quality Gates Checklist" per participant
- [ ] Print one "AI Code Governance Framework" template per participant
- [ ] Print one "Vendor Risk Assessment" matrix per participant
- [ ] Print "Security Considerations Checklist" per participant
- [ ] Print "Competitive Advantage Planning" worksheet per participant
- [ ] Print "18-Month Strategic Roadmap" template per participant
- [ ] Print "Implementation Planning" sheets per participant
- [ ] Prepare sample governance policies (2-3 examples from different organizations)
- [ ] Prepare risk assessment scenarios for group exercise

**Room Setup:**
- [ ] Arrange for group work areas (teams of 4-5)
- [ ] Set up wall space for roadmap planning exercise
- [ ] Arrange chairs for presentations and discussions
- [ ] Have sticky notes, markers, and index cards available
- [ ] Prepare flip charts for strategy work
- [ ] Test any legal/compliance reference documents

### 24 Hours Before Class

**Participant Communications:**
- [ ] Send reminder with Day 3 focus: implementation and governance
- [ ] Ask participants to bring Days 1-2 homework
- [ ] Request they think about their organization's governance maturity
- [ ] Suggest they consider security/compliance needs in advance
- [ ] Provide final logistics (parking, timing, etc.)

**Last-Minute Checks:**
- [ ] Verify all templates are current
- [ ] Review case studies for relevance and appropriateness
- [ ] Ensure policy examples are anonymized if needed
- [ ] Test any legal/compliance resource links
- [ ] Prepare examples of effective vs. ineffective policies

### Day of Class (Arrive 30 minutes early)

**Room Verification:**
- [ ] Test AV equipment for presentations
- [ ] Check room temperature and lighting
- [ ] Arrange materials at tables or entry point
- [ ] Verify WiFi is functioning
- [ ] Set up large wall space for roadmap exercise

**Technical Setup:**
- [ ] Open presentation materials
- [ ] Have backup copies accessible
- [ ] Test any document sharing or collaboration tools
- [ ] Verify printer/copy availability if needed

---

## Learning Objectives

By the end of Day 3, participants will be able to:

### Knowledge Objectives
- **Understand** how quality gates need to evolve with AI-assisted development
- **Explain** AI code governance policies and why they matter
- **Identify** vendor risks and mitigation strategies
- **Recognize** security and compliance implications of AI tool adoption
- **Articulate** how to build competitive advantages beyond tool adoption
- **Understand** the critical success factors for AI adoption journeys

### Skill Objectives
- **Create** quality gate frameworks appropriate for their organization
- **Develop** governance policies that enable innovation while managing risk
- **Conduct** vendor risk assessments and manage vendor relationships
- **Build** security considerations into AI adoption plans
- **Design** 18-month strategic roadmaps for AI adoption
- **Create** detailed implementation plans with clear ownership and timelines

### Attitude Objectives
- **Adopt** a governance-first approach to technology adoption
- **Commit** to balancing speed with safety and quality
- **Recognize** that governance enables innovation, not inhibits it
- **Embrace** vendor management as critical responsibility
- **Develop** strategic thinking about competitive advantage
- **Commit** to continuous risk management and adaptation

---

## Tool and Software Requirements

### Required Software/Platforms

| Tool | Version | Purpose | Validation |
|------|---------|---------|-----------|
| Spreadsheet Software | Excel 2019+ or Google Sheets | Governance templates, risk matrices, roadmap planning | Test: Create sample governance doc |
| Word Processor | Word 2019+ or Google Docs | Policy documents, implementation plans | Test: Create sample policy |
| Web Browser | Chrome/Firefox/Safari (latest) | Accessing vendor information, compliance resources | Test: Verify compliance/security resource sites |
| Presentation Software | PowerPoint or Google Slides | Final presentations (optional) | Test: Verify templates work |
| Collaboration Tool (Optional) | Miro, Mural, or Google Docs | Real-time strategy planning | Test: Create sample roadmap board |

### Hardware Requirements

| Item | Specification | Notes |
|------|---------------|-------|
| Projector | 2500+ lumens minimum | For 1920x1080 resolution |
| Large Display/Whiteboard | 8'+ width | For roadmap planning exercise |
| Audio System | Microphone + speakers | For presentations and group discussions |
| Flip Charts | 3-5 pads | For group strategy work |
| Markers | Various colors | Multiple sets for group work |

### Reference Materials to Have Ready

1. **Printed Materials:**
   - Quality Gates Checklist
   - AI Code Governance Framework template
   - Vendor Risk Assessment matrix
   - Security Considerations Checklist
   - Competitive Advantage Planning worksheet
   - 18-Month Strategic Roadmap template

2. **Digital Resources:**
   - Case studies of governance failures and successes
   - Sample AI policies from real organizations
   - Vendor evaluation checklists
   - Security compliance frameworks (GDPR, HIPAA, etc.)
   - Implementation timeline examples

3. **Legal/Compliance References:**
   - Current data protection regulations relevant to participants' regions
   - Security compliance standards (SOC 2, ISO 27001, etc.)
   - Industry-specific requirements (if known)
   - Contract template requirements

---

## Daily Schedule

### Recommended Session Structure (3-4 hours)

| Time | Duration | Activity | Materials | Notes |
|------|----------|----------|-----------|-------|
| 6:00 PM | 5 min | Welcome & Workshop Recap | Projector | Connect all three days |
| 6:05 PM | 10 min | Homework Review Highlights | Notes from Days 1-2 | Quick patterns observed |
| 6:15 PM | 20 min | Quality Gates Framework | Slides, checklists | Reimagining development process |
| 6:35 PM | 20 min | AI Code Governance | Slides, policy templates | Policies that enable innovation |
| 6:55 PM | 10 min | **BREAK** | Refreshments | Informal discussion |
| 7:05 PM | 20 min | Vendor Risk Assessment | Risk matrix, examples | Managing vendor relationships |
| 7:25 PM | 15 min | Security Considerations | Checklist, case studies | Protecting code and data |
| 7:40 PM | 30 min | Group Exercise: Build Governance | Templates, flip charts | Participants draft their policies |
| 8:10 PM | 15 min | Competitive Advantage Planning | Worksheet, examples | Beyond tool adoption |
| 8:25 PM | 25 min | 18-Month Roadmap Planning | Template, sticky notes | Strategic roadmap development |
| 8:50 PM | 15 min | Implementation Planning | Planning templates | From strategy to action |
| 9:05 PM | 15 min | Presentations & Discussion | Flip charts | Groups share roadmaps |
| 9:20 PM | 10 min | Next Steps & Commitment | Action planning sheet | What will you do first? |
| 9:30 PM | 5 min | Closing & Celebration | None | Wrap up three-day workshop |

**Total Recommended Duration:** 3 hours 30 minutes  
**Flexible Options:** Can extend to 4 hours by adding more group work time

---

## Detailed Topic Guide

### Topic 1: Homework Review & Context Setting (15 minutes)

**Objective:** Connect Days 1-2 to Day 3 governance work

**Key Points to Convey:**
- You've built understanding of tools and people
- Now comes organizational structure to support both
- Governance isn't bureaucracy; it's enablement
- Quality and innovation go together when governance is right

**Detailed Content Outline:**

**A. Three-Day Journey Recap (5 minutes)**

**Show progression:**
- Day 1: "Which tools should we adopt?" (Decision framework)
- Day 2: "How do we support our people?" (Human factors)
- Day 3: "How do we do this sustainably?" (Organizational structures)

**B. Homework Insights (10 minutes)**

**Share patterns you noticed:**
- Team compositions (which types dominate different organizations?)
- Most common skill gaps (usually prompt engineering and critical evaluation)
- Conversation concerns (what worried people most?)
- Development priorities identified

**Ask:**
- "Who's planning to have these conversations this week?"
- "What was most useful from Days 1-2?"
- "What questions do you still have?"

**Transition:**
"Today we make sure your organization can support all of this. Governance, policies, and strategic planning create the container for success."

---

### Topic 2: Quality Gates Reimagined (20 minutes)

**Objective:** Help participants understand how to maintain quality with AI-assisted development

**Why This Matters:**
- AI changes what you need to check, but quality gates remain critical
- Traditional gates miss AI-specific risks
- Quality gates also protect from over-reliance on AI
- Consistency across team is impossible without clear standards

**Key Teaching Approach:**
- Show why old gates aren't sufficient
- Introduce new framework that builds on traditional approach
- Provide concrete implementation examples
- Help participants think about their own context

**Detailed Content Outline:**

**A. Traditional Gates Still Apply (5 minutes)**

**Why they matter:**
1. **Requirements and Design Gate:** Are we solving the right problem?
2. **Code Generation Gate:** Is the code generated properly?
3. **Code Review Gate:** Is this acceptable for production?
4. **Testing Gate:** Does it work as intended?
5. **Production Monitoring:** Are we catching issues early?

**How traditional gates work:**
- Check that requirements are clear before coding
- Verify code passes automated tests
- Manual review by another developer
- Performance and integration testing
- Monitoring in production

**Still necessary because:**
- AI doesn't eliminate quality risks
- Human judgment remains essential
- Failures in requirements propagate through entire system
- Testing catches both AI and human errors

**B. New Gate: Understanding (8 minutes)**

**The critical addition:**
Before code can pass review, developer must understand it.

**Why this matters:**
- AI-generated code works but might not match your patterns
- Developer needs to own the code
- Blind acceptance creates maintenance problems
- This prevents over-reliance

**How to implement:**
1. **In code review:** "Can you explain this section?"
2. **During pair programming:** Watch developer walk through logic
3. **In design discussion:** Ensure they chose the approach consciously
4. **In testing:** Verify they understand edge cases, not just run tests

**Red flags:**
- "I'm not really sure what this does"
- "I just accepted what AI generated"
- "I didn't really review it"
- Code doesn't match existing patterns without explanation

**Green flags:**
- Clear explanation of logic and approach
- Thoughtful review of AI output
- Conscious choices about code style and structure
- Comfort with maintenance and changes

**C. New Gate: Context Fit (7 minutes)**

**The architectural addition:**
Does the solution fit how you do things?

**Why this matters:**
- AI generates technically correct but potentially wrong solutions
- Your codebase has patterns and conventions
- Over-engineering happens when AI generates "complete" solutions
- Inconsistency creates maintenance burden

**What to check:**
- Does it follow team coding standards?
- Does it match architectural patterns?
- Could it be simplified?
- Does it use existing utilities and patterns?
- Is it over-engineered for the problem?

**How to implement:**
1. **Style consistency:** Linting and automated checks handle most
2. **Pattern matching:** Code review for architectural fit
3. **Complexity assessment:** Is it the simplest solution?
4. **Refactoring:** Extract patterns and reuse

**D. Implementation Recommendations (7 minutes)**

**Suggested Quality Gate Sequence:**

```
Requirements & Design Gate
    ↓ (Is the plan clear and agreed?)
Code Generation Gate
    ↓ (Did developer generate code thoughtfully?)
Understanding Gate
    ↓ (Can developer explain it?)
Context Fit Gate
    ↓ (Does it match our patterns?)
Code Review Gate
    ↓ (Is it good code?)
Testing Gate
    ↓ (Does it work correctly?)
Production Gate
    ↓ (Are we monitoring properly?)
Success!
```

**For each gate, define:**
- Who is responsible?
- What's being checked?
- What passes vs. fails?
- What's the escalation?

**Teaching Tips:**
- Quality gates aren't punishment; they're protection
- Consistency matters for maintainability
- Everyone passes gates eventually; gates just ensure quality
- Automate what you can; focus human review on judgment

---

### Topic 3: AI Code Governance Framework (20 minutes)

**Objective:** Help participants create governance policies that enable innovation while managing risk

**Why This Matters:**
- Without clear policies, problems accumulate
- Different organizations need different policies
- Policies should be enabling, not restrictive
- Written policies are easier to enforce and update

**Key Teaching Approach:**
- Show governance as enablement, not restriction
- Present core policy areas to consider
- Help participants draft initial policies
- Provide flexibility for customization

**Detailed Content Outline:**

**A. Eight Core Policy Areas (15 minutes)**

**1. AI Tool Approval Policy**

**The question:** Who decides which AI tools can be used?

**Options:**
- Individual developers choose freely
- Team lead approval required
- Engineering manager approval required
- CTO/security team approval required
- Different tools, different levels

**Recommendation:**
- Low-risk tools (IDE suggestions, code formatting): Developer choice
- Medium-risk tools (Copilot, ChatGPT for code): Team lead review
- High-risk tools (Custom AI, proprietary data): CTO/Security approval

**Implementation:**
- Create tool tiers
- Define approval process for each tier
- Maintain approved tool list
- Review quarterly

**2. Disclosure Requirements**

**The question:** When must developers disclose AI usage?

**Options:**
- Never (AI is assumed/allowed)
- In code comments
- In commit messages
- In code review
- For substantial code sections only
- Always disclosed

**Recommendation:**
- Disclosed in code comments for clarity
- Mentioned in commit messages for transparency
- Discussed in code review as normal
- Not a violation, but a communication tool

**Implementation:**
- Simple comment format: `# Generated with AI tool [X], verified by [developer]`
- Normalized as information, not confession
- Encourages honest disclosure

**3. Code Ownership**

**The question:** Who owns AI-generated code?

**Options:**
- The company (most organizations)
- The developer (contract work)
- The AI vendor (usually not)
- Legally unclear

**Recommendation:**
- Code written by your employees, whether AI-assisted or not, belongs to your company
- Have this in employment agreements and AI tool terms
- Understand vendor policies on training data

**Implementation:**
- Legal review of AI tool contracts
- Clear employment agreement language
- Documented understanding across team

**4. Acceptable Use Policy**

**The question:** What can AI tools be used for?

**Can use for:**
- Writing new code
- Refactoring existing code
- Writing tests
- Generating documentation
- Code review assistance
- Learning and training
- Architecture suggestions

**Cannot use for:**
- Copying proprietary competitor code
- Generating code without review (for production)
- Security-critical code without additional review
- Regulated functionality without audit trail
- Code with customer data without approval

**Implementation:**
- Clear written guidelines
- Training on appropriate use
- Regular reminders and reinforcement
- Escalation path for unclear cases

**5. Data Privacy Policy**

**The question:** What code can be sent to AI tools?

**Key concerns:**
- Is your code confidential?
- Does it contain customer data?
- Does it contain credentials or secrets?
- Are there regulatory concerns?

**Recommendation:**
- Public domain code: Any tool
- Company-specific, non-sensitive: Approved vendor tools with privacy agreements
- Sensitive/proprietary: Only on-premise or private tools
- Regulated data: Special approval required

**Implementation:**
- Classify code by sensitivity
- Create tool recommendations by classification
- Employee training on classification
- Regular audits of compliance

**6. Quality Standards**

**The question:** What standards apply to AI-generated code?

**Standards:**
- Must pass all automated tests
- Reviewed by another developer
- Meets code coverage requirements
- Follows team coding standards
- Understood by submitting developer
- No integration issues

**Implementation:**
- Same standards for AI and human-written code
- No special exceptions
- Clear testing requirements
- Regular quality reporting

**7. Security Requirements**

**The question:** Special considerations for security?

**Requirements:**
- All AI-generated code passes security scanning
- Authentication/authorization code receives extra review
- Penetration testing includes AI-generated code
- Regular audits of AI tool usage
- Incident response includes AI components

**Implementation:**
- Integrated security scanning in CI/CD
- Security team awareness of AI usage
- Training on security implications
- Regular reviews of security incidents

**8. Training and Onboarding**

**The question:** How do new developers learn about AI policies?

**Requirements:**
- All new developers complete AI tool training
- Understand policies and guidelines
- Sign acknowledgment of policies
- Shadow experienced developer using AI
- Gradual ramp-up on tool access

**Implementation:**
- Mandatory training module
- Policy document in employee handbook
- Pairing with experienced developer
- Regular check-ins during onboarding

**B. Policy Development Exercise (5 minutes)**

**Guide participants through thinking about their own:**

**Starting questions:**
- "Which policies are most important for your organization?"
- "What's your risk tolerance?"
- "What regulatory concerns do you have?"
- "What problems have you already experienced?"

**Recommend starting with:**
1. Tool Approval (control what's used)
2. Disclosure (transparency)
3. Quality Standards (consistency)
4. Data Privacy (protection)

**Expand to others as needed.**

**Teaching Tips:**
- Governance should be enabling, not bureaucratic
- Policies can change as organization learns
- Start simple; add complexity as needed
- Employee buy-in matters for compliance
- Regular review and updates are essential

---

### Topic 4: Vendor Risk Assessment (20 minutes)

**Objective:** Help participants manage vendor relationships and mitigate vendor-related risks

**Why This Matters:**
- You're dependent on vendor stability and reliability
- Vendor issues become your issues
- Early risk assessment prevents surprises
- Contractual protections matter

**Key Teaching Approach:**
- Show common vendor risks
- Provide assessment framework
- Help participants think about their vendors
- Provide contract protection guidance

**Detailed Content Outline:**

**A. Key Vendor Risk Categories (12 minutes)**

**1. Vendor Stability Risks**

**What can go wrong:**
- Company goes out of business
- Gets acquired and product discontinued
- Changes pricing dramatically
- Changes service model
- Key team members leave

**How to assess (1-5 scale):**
- Years in business: Newer companies = higher risk
- Customer base size: Smaller base = higher risk
- Financial stability: Evidence of profitability
- Leadership experience: Consistent leadership = lower risk
- Market position: Market leader = lower risk

**Mitigation:**
- Review financial data (Crunchbase, SEC filings)
- Ask for customer references
- Understand funding model
- Plan for alternatives
- Negotiate transition terms

**2. Product Maturity Risks**

**What can go wrong:**
- Product discontinued
- Features removed
- Major bugs introduced
- Roadmap changed
- Support deteriorates

**How to assess:**
- Product age: Newer = higher risk
- Feature completeness: Missing features = problem
- Release frequency: No releases = problem
- Bug fix responsiveness: Slow = problem
- Roadmap clarity: Unclear future = risk

**Mitigation:**
- Review release notes regularly
- Monitor feature roadmap
- Track bug resolution time
- Join user communities for feedback
- Have backup tools identified

**3. Lock-in Risks**

**What can go wrong:**
- Can't export data when you leave
- Switching costs are prohibitive
- Vendor controls your workflow
- No APIs to integrate with your tools
- Proprietary formats

**How to assess:**
- Data portability: Can you get your data out?
- API availability: Can you integrate it?
- Standard formats: Do they use industry standards?
- Integration dependencies: Are you locked into their ecosystem?
- Alternative tools: How many competitors exist?

**Mitigation:**
- Require data export in standard formats
- Use API when possible (avoid proprietary integrations)
- Multi-vendor strategy (don't rely on one)
- Understand switching costs upfront
- Contractual data deletion rights

**4. Support and Documentation Risks**

**What can go wrong:**
- Can't get help when you need it
- Documentation is incomplete or poor
- Community support is non-existent
- Support changes (paid-only, response time degrades)
- Training resources disappear

**How to assess:**
- Documentation quality: Is it usable?
- Support availability: How many support tiers?
- Response time: What's the SLA?
- Community size: Active or dead?
- Training resources: What's available?

**Mitigation:**
- Require SLA in contracts
- Negotiate support levels
- Build internal expertise
- Document your own processes
- Invest in team training upfront

**5. Pricing Stability Risks**

**What can go wrong:**
- Prices increase dramatically
- Pricing model changes (per-user to per-transaction, etc.)
- Free tier discontinued
- Hidden fees appear
- Negotiated terms change

**How to assess:**
- Pricing model: How transparent?
- Price change history: How often do they increase?
- Contract terms: Lock-in period?
- Volume discounts: Available?
- Trial availability: Can you test before buying?

**Mitigation:**
- Lock-in pricing in multi-year contracts
- Require notice for price increases
- Negotiate volume discounts
- Include exit clauses
- Budget for potential increases

**B. Risk Assessment Matrix (5 minutes)**

**For each vendor, score:**

**Risk Category | Impact (1-5) | Likelihood (1-5) | Priority | Mitigation**

**Example:**
- Vendor discontinues product | Impact: 5 | Likelihood: 2 | Priority: High
- Mitigation: Have backup tool identified, contractual transition support

**Teaching Tips:**
- Show real examples (Evernote, Google Reader, etc.)
- Emphasize that risk management is ongoing
- Plan for multiple vendors in key areas
- Read contracts carefully
- Negotiate important protections

---

### Topic 5: Security and Compliance Considerations (15 minutes)

**Objective:** Help participants build security into AI adoption plans

**Why This Matters:**
- Security risks are real and increasing
- Compliance requirements vary by industry
- Early planning is cheaper than retrofitting
- Customer trust depends on security
- Regulatory violations are costly

**Key Teaching Approach:**
- Present concrete security concerns
- Show compliance frameworks
- Help participants assess their risks
- Provide practical mitigation steps

**Detailed Content Outline:**

**A. Core Security Concerns (10 minutes)**

**1. Data Security**

**What's at risk:**
- Code you send to AI tools
- Confidential business logic
- Customer data
- Security credentials
- Intellectual property

**Questions to ask:**
- Where is my data stored?
- Is it encrypted in transit?
- Is it encrypted at rest?
- Can the vendor use it for training?
- What happens if there's a breach?
- How long is it retained?

**Mitigation:**
- Read privacy policies carefully
- Use tools that don't train on your data
- Encrypt data before sending (if possible)
- Use on-premise solutions for sensitive code
- Regular audits of tool usage
- Data classification system

**2. Code Security**

**What's at risk:**
- Vulnerabilities introduced by AI
- Dependency vulnerabilities
- Authentication/authorization flaws
- Input validation gaps
- Hardcoded credentials

**How AI creates risks:**
- AI may suggest vulnerable patterns
- Training data may include insecure code
- AI may miss context-specific security needs
- Generated code may have novel vulnerabilities

**Mitigation:**
- Security scanning in CI/CD pipeline
- Code review with security focus
- Dependency scanning for vulnerabilities
- Security training for team
- Threat modeling discussions
- Regular penetration testing

**3. Compliance Risks**

**What's at risk:**
- Regulatory violations
- Data protection failures
- Audit trail gaps
- Industry-specific requirements
- International regulations

**Key regulations to consider:**
- GDPR (EU data protection)
- HIPAA (healthcare)
- PCI DSS (payment cards)
- SOC 2 (service organizations)
- CCPA (California privacy)

**Mitigation:**
- Understand applicable regulations
- Document AI tool usage
- Maintain audit trails
- Ensure vendor compliance
- Legal review of tool contracts
- Regular compliance audits

**4. Intellectual Property Risks**

**What's at risk:**
- Code similarities to existing open-source
- Training data concerns
- Liability for similar code generation

**How AI creates risks:**
- AI trained on public code (including open-source)
- Possible generation of similar code
- Vendor liability policies
- Your liability to customers

**Mitigation:**
- Understand vendor training data policies
- License scanning on generated code
- Review vendor liability coverage
- Insurance for code generation liability
- Legal guidance for your industry

**B. Security Considerations Checklist (5 minutes)**

**Data Security:**
- [ ] Understand what data AI tool collects
- [ ] Know where data is stored
- [ ] Verify encryption in transit
- [ ] Verify encryption at rest
- [ ] Review data retention policies
- [ ] Confirm data deletion procedures
- [ ] Check data residency requirements
- [ ] Review third-party data sharing

**Access Control:**
- [ ] Implement least-privilege access
- [ ] Use SSO if available
- [ ] Enable multi-factor authentication
- [ ] Review user access regularly
- [ ] Have process for removing access
- [ ] Monitor for suspicious activity

**Code Security:**
- [ ] Scan generated code for vulnerabilities
- [ ] Review authentication code specially
- [ ] Check for hardcoded credentials
- [ ] Validate input handling
- [ ] Review error messages
- [ ] Test for common vulnerabilities

**Intellectual Property:**
- [ ] Understand code ownership policies
- [ ] Review AI training data policies
- [ ] Protect proprietary algorithms
- [ ] Check license compliance
- [ ] Document code sources
- [ ] Review tool terms of service

**Compliance:**
- [ ] Identify applicable regulations
- [ ] Verify vendor compliance certifications
- [ ] Review audit capabilities
- [ ] Document AI tool usage
- [ ] Train team on compliance
- [ ] Plan for regulatory audits

**Incident Response:**
- [ ] Plan for data breach scenarios
- [ ] Know vendor notification procedures
- [ ] Have rollback procedures ready
- [ ] Document incident response steps
- [ ] Test incident response plan

**Teaching Tips:**
- Security isn't perfect; it's about managing risk
- Different organizations have different risk profiles
- Regular reviews and updates are essential
- Team training is critical
- Document everything for compliance

---

### Topic 6: Competitive Advantage Planning (15 minutes)

**Objective:** Help participants think strategically about AI differentiation

**Why This Matters:**
- AI tools are becoming commodities
- Using same tools doesn't guarantee competitive advantage
- Real advantage comes from execution and integration
- Long-term thinking prevents reactive decisions
- Competitive advantage attracts talent and customers

**Key Teaching Approach:**
- Show why tool adoption alone isn't enough
- Present multi-level advantage framework
- Help participants identify their unique opportunities
- Connect advantages to strategy

**Detailed Content Outline:**

**A. Levels of AI Advantage (12 minutes)**

**Level 1: Tool Adoption (No Advantage)**
- What: Using AI tools like everyone else
- Who: Early adopters, innovators
- Duration: 6-12 months
- Advantage: None (everyone else adopts too)
- Example: "We use GitHub Copilot"

**Level 2: Effective Usage (Temporary Advantage)**
- What: Using tools better than competitors through training and process
- Who: Organizations with good execution
- Duration: 12-24 months
- Advantage: Temporary (others learn from you)
- Example: "Our developers are trained in prompt engineering; we use AI more effectively"

**Level 3: Custom Integration (Medium-term Advantage)**
- What: Integrating AI deeply into your workflows and tools
- Who: Organizations with technical capability
- Duration: 2-3 years
- Advantage: Medium (copying requires significant investment)
- Example: "We've integrated AI into our code review process and deployment pipeline"

**Level 4: Proprietary AI (Long-term Advantage)**
- What: Building AI capabilities specific to your domain
- Who: Large organizations or AI-focused companies
- Duration: 3-5+ years
- Advantage: Long-term (hard to copy)
- Example: "We've built custom AI trained on our codebase and business logic"

**Where is your organization?**
- Most start at Level 1
- Can reach Level 2 quickly with execution
- Level 3 requires architectural thinking
- Level 4 requires significant investment

**B. Advantage Sources (8 minutes)**

**1. Domain Knowledge Advantages**

**What:** Your specific industry expertise

**Examples:**
- Deep understanding of customer problems
- Knowledge of domain-specific patterns
- Industry-specific security requirements
- Regulatory knowledge

**How to leverage:**
- Use domain knowledge in prompts to AI
- Train AI on your specific problems
- Apply AI to problems others haven't solved
- Build custom tools for your domain

**2. Technical Advantages**

**What:** Unique technical capabilities

**Examples:**
- Custom tooling and infrastructure
- Unique architecture patterns
- Performance optimizations
- Specialized infrastructure

**How to leverage:**
- Integrate AI into your custom systems
- Build AI-specific optimizations
- Create tool combinations unique to you
- Optimize for your specific scale/requirements

**3. Team Advantages**

**What:** Quality of your people and culture

**Examples:**
- Skilled developers who learn quickly
- Effective processes and collaboration
- Strong engineering culture
- Fast learning and adaptation

**How to leverage:**
- Invest in training early
- Build culture that embraces learning
- Develop mentoring programs
- Create environment where experiments are safe

**4. Data Advantages**

**What:** Unique datasets and insights

**Examples:**
- Proprietary customer data
- Performance metrics and learnings
- Historical problem-solution mappings
- Competitive intelligence

**How to leverage:**
- Use data to train custom models (if applicable)
- Apply data-driven decisions to AI adoption
- Learn from your own patterns faster
- Benchmark against industry

**C. 12-Month Advantage Building Plan (5 minutes)**

**Months 1-3: Foundation (Tool Adoption)**
- Introduce AI tools
- Basic training
- Establish baseline metrics
- Identify early opportunities

**Months 4-6: Execution (Effective Usage)**
- Expand training to whole team
- Document best practices
- Measure productivity gains
- Identify custom opportunities

**Months 7-9: Innovation (Custom Integration)**
- Integrate into workflows
- Build custom tooling
- Share innovations across teams
- Competitive analysis (what are we uniquely good at?)

**Months 10-12: Strategy (Next Phase)**
- Plan Level 3-4 investments
- Build business case for custom solutions
- Develop domain-specific capabilities
- Plan for next 12 months

**Teaching Tips:**
- Advantage comes from execution, not tools
- Multiple sources of advantage are more resilient
- Continuous adaptation is essential
- Learning organization culture is key
- Document and share what works

---

### Topic 7: 18-Month Strategic Roadmap & Implementation (40 minutes)

**Objective:** Help participants create realistic, actionable implementation plans

**Why This Matters:**
- Strategy without execution is just words
- Roadmaps provide visibility and alignment
- Timelines prevent either rushing or endless delay
- Clear ownership ensures accountability
- Phased approach allows learning and adjustment

**Key Teaching Approach:**
- Provide roadmap template and examples
- Help participants work through their own
- Connect roadmap to all prior learning
- Make it action-oriented, not theoretical

**Detailed Content Outline:**

**A. Strategic Roadmap Framework (10 minutes)**

**Four Phases, Four Quarters**

**Phase 1: Months 1-3 (Foundation)**

**Goals:**
- Establish baseline metrics
- Complete tool evaluation
- Identify pilot projects
- Build governance framework

**AI Tools to Introduce:**
- Start with 1-2 tools (not 5)
- Focus on most commonly used (code completion)
- Get team using and evaluating
- Measure impact

**Training Plan:**
- All-hands introduction (what is AI?)
- Basic tool training for pilot team
- Security/compliance training
- 1:1 support for early adopters

**Success Metrics:**
- Pilot team adoption rate (target: 75%+)
- Developer satisfaction with tools (target: 3.5+/5)
- No security incidents
- Positive feedback on training

**Budget:** $20K-50K (typically: training, tools, time)

**Phase 2: Months 4-6 (Expansion)**

**Goals:**
- Expand to wider team
- Refine processes based on pilot learning
- Address emerging concerns
- Expand tool set if warranted

**Process Changes:**
- Updated code review procedures
- New quality gate for "understanding"
- Performance review updates (if not done in parallel)
- Governance policies finalized

**Additional Tools:**
- Add secondary tools based on pilot learnings
- Consider domain-specific tools
- Don't add too many (maintain focus)

**Success Metrics:**
- Adoption rate expands (target: 50%+ of developers)
- Quality metrics stable or improved
- Team member concerns addressed
- Governance policies in place

**Budget:** $30K-75K (wider adoption, ongoing training)

**Phase 3: Months 7-12 (Optimization)**

**Goals:**
- Mature adoption practices
- Develop advanced skills
- Build competitive advantages
- Address remaining gaps

**Advanced Capabilities:**
- Advanced prompt engineering training
- Domain-specific AI applications
- Workflow optimizations
- Integration into CI/CD pipeline

**Team Development:**
- Pragmatists become mentors
- Skeptics move toward pragmatism
- Resisters given options (find role, move on)
- New developers onboarded to AI-first process

**Success Metrics:**
- 80%+ active adoption
- Measurable productivity gains (target: 10-20%)
- Code quality maintained or improved
- Team satisfaction improving

**Budget:** $50K-100K (optimization, training, tooling)

**Phase 4: Months 13-18 (Innovation)**

**Goals:**
- Build custom solutions
- Develop competitive advantages
- Plan for evolution of AI landscape
- Prepare for next wave of AI tools

**Custom Solutions:**
- AI-specific workflows for your domain
- Custom integrations
- Process innovations
- Tool combinations unique to your organization

**Competitive Advantages:**
- What are you uniquely good at?
- How do you leverage AI differently?
- Where can you lead industry?
- What's your differentiator?

**Success Metrics:**
- Competitive advantages identified and building
- Long-term team satisfaction high
- Sustainable competitive position
- Ready for next generation of tools

**Budget:** $75K-150K (innovation investment)

**B. Key Planning Considerations (8 minutes)**

**Timing Questions:**
- "Can we move faster? Should we?"
- "Which teams pilot first?"
- "How much training is enough?"
- "When do we declare 'done'?"

**Resource Questions:**
- "Who owns implementation?"
- "How much time does this need?"
- "What budget is required?"
- "Who needs to be involved?"

**Risk Questions:**
- "What could go wrong?"
- "How will we recover?"
- "What's our exit strategy?"
- "Who do we escalate to?"

**Success Questions:**
- "How will we know it's working?"
- "What metrics matter?"
- "Who decides if we continue?"
- "When do we review and adjust?"

**C. Implementation Planning Exercise (22 minutes)**

**Phase 1: Small Group Planning (15 minutes)**

**Setup:**
- Divide participants into groups of 3-4
- Each group represents an organization
- Provide roadmap templates and markers
- Access to flip charts or large paper

**Task:**
1. Define your organization (size, industry, baseline)
2. Set 18-month goals
3. Identify key phases and activities
4. Assign ownership for each phase
5. Identify key milestones and success metrics
6. Note risks and mitigation strategies

**Guidance:**
- Be realistic about resources and timelines
- Connect to governance from earlier in class
- Plan for people development from Day 2
- Build in learning loops and adjustments

**Phase 2: Group Presentations (7 minutes)**

**Format:**
- Each group presents their roadmap (2-3 minutes)
- Focus on key decisions and milestones
- Highlight unique aspects of their plan

**Discussion:**
- Ask clarifying questions
- Point out connections to other learning
- Validate approaches and challenge assumptions
- Celebrate good thinking

**Debrief:**
- "What was hard about planning this?"
- "What surprised you?"
- "What will you actually do first?"
- "What obstacles do you anticipate?"

**Teaching Tips:**
- Reality-check roadmaps but don't criticize
- Emphasize that roadmaps change
- Celebrate good thinking, not just perfect plans
- Encourage discussion and questions
- Connect back to all three days of learning

---

## Activities and Exercises

### Exercise 1: Quality Gate Development (20 minutes)

**Objective:** Help participants design quality gates appropriate for their organization

**Materials Needed:**
- Quality Gates Checklist template
- Flip chart paper and markers
- Sample code snippets (AI-generated and human-written)

**Activity:**

**1. Setup (3 minutes)**
- Show example quality gate flow
- Walk through each gate type

**2. Individual Reflection (5 minutes)**
- Participants think about their current process
- What gates do you have?
- What's missing?
- Where are the gaps?

**3. Small Group Development (10 minutes)**
- Groups of 3-4 develop their organization's gates
- Define for each gate:
  - Who's responsible?
  - What's being checked?
  - What passes/fails?
  - Escalation process

**4. Gallery Walk (2 minutes)**
- Post flip charts around room
- Participants walk and see others' approaches

**Debrief:**
- "What gates did everyone include?"
- "Where did approaches differ?"
- "What surprised you?"

---

### Exercise 2: Governance Policy Development (30 minutes)

**Objective:** Help participants draft governance policies for their organization

**Materials Needed:**
- AI Code Governance Framework template
- Policy examples (2-3 from different organizations)
- Flip chart paper and markers
- Sample scenarios (appropriate use questions)

**Activity:**

**1. Setup (5 minutes)**
- Show three sample policies from different organizations
- Discuss why they differ
- Explain: "Policies should match your risk tolerance"

**2. Small Group Work (15 minutes)**
- Groups select one policy area to draft:
  - Tool Approval
  - Disclosure Requirements
  - Acceptable Use
  - Data Privacy
  - Quality Standards
  - Security Requirements

- For their policy, define:
  - Goal (what are we trying to achieve?)
  - What's allowed/not allowed
  - How it will be enforced
  - How it will be communicated

**3. Group Presentations (8 minutes)**
- Each group presents their policy draft
- 1-2 minutes per group
- Focus on key decisions and reasoning

**4. Discussion (2 minutes)**
- "How will you communicate these?"
- "How will you handle violations?"
- "When will you review/update?"

**Debrief:**
- Affirm that policies are starting points, not finished products
- Policies will evolve as you learn
- Communication and buy-in matter
- Regular review is essential

---

### Exercise 3: 18-Month Roadmap Planning (30 minutes)

**Objective:** Help participants create realistic implementation roadmaps

**Materials Needed:**
- 18-Month Roadmap template
- Sticky notes in multiple colors
- Flip chart paper or large wall space
- Markers
- Sample roadmaps (2-3 examples)

**Activity:**

**1. Setup (3 minutes)**
- Show sample roadmaps
- Explain four phases
- Highlight key decision points

**2. Individual Planning (5 minutes)**
- Participants sketch their own roadmap outline
- Key phases and milestones
- Major activities per phase

**3. Small Group Development (15 minutes)**
- Groups of 3-4 build detailed roadmap
- Phase by phase:
  - Goals
  - Key activities
  - Tools to introduce
  - Team changes needed
  - Success metrics
  - Budget estimates
- Use sticky notes to stay flexible
- Iterate as discussion refines thinking

**4. Presentations & Discussion (7 minutes)**
- Each group presents roadmap
- Focus on rationale for pacing
- Key risks and mitigation
- First concrete actions

**Debrief:**
- "What are your first 30-day priorities?"
- "What will be hardest?"
- "Who do you need to involve?"
- "When will you start?"

**Teaching Tips:**
- Roadmaps don't have to be perfect
- Pacing matters more than features
- Learning loops are essential
- Flexibility is important—plans change
- Getting started is the key

---

## Assignments

### Final Assignment: Organizational AI Adoption Plan

**Assignment: Create Your Adoption Plan**

**Due:** One week after workshop

**Scope:** Create a preliminary organizational AI adoption plan for your organization

**Components:**

**1. Current State Assessment (15 minutes)**
- Tool readiness (from Day 1 homework)
- Team readiness (from Day 2 homework)
- Governance maturity
- Risk profile
- Competitive position

**2. Governance Framework (30 minutes)**
- Identify 3-5 most important policy areas
- Draft initial policies for each
- Identify governance owner
- Plan for rollout and communication

**3. 18-Month Strategic Roadmap (30 minutes)**
- Define 4 phases and key goals
- Identify tools, training, and process changes
- Assign ownership and timeline
- Define success metrics
- Estimate budget

**4. Risk Assessment and Mitigation (15 minutes)**
- Identify top 3 risks (organizational, technical, people)
- Define mitigation strategies
- Identify contingency plans
- Name risk owner

**5. First 90 Days Action Plan (15 minutes)**
- What's your first action (before next week)?
- Days 1-30: Key activities and decisions
- Days 31-60: Expansion or refinement
- Days 61-90: Assessment and next phase planning
- Ownership and accountability

**Submission Format:**
- Written document (5-10 pages)
- Roadmap (visual timeline, can be simple)
- Bring to final team meeting or share with your manager

**Grading Rubric:**

| Component | Excellent | Good | Developing |
|-----------|-----------|------|-----------|
| Current State | Accurate, insightful, balanced | Clear and accurate | Basic understanding |
| Governance | Thoughtful policies matched to context | Clear policies, some thought | Generic or incomplete |
| Roadmap | Realistic pacing, clear phases, connected | Good structure, reasonable | Vague or over-ambitious |
| Risk Mgmt | Thoughtful risks, real mitigations | Clear risks identified | Limited risk thinking |
| Action Plan | Specific, actionable, realistic | Clear but could be more specific | Vague or overly ambitious |

**Usage Notes:**
- This plan is a working document, not final
- Share with leadership for feedback and approval
- Revisit and update quarterly
- Use for quarterly business reviews
- Reference when making tool/process decisions

---

## Assessment and Evaluation

### Formative Assessment (During Class)

**Check for Understanding:**

**After Quality Gates section:**
- Ask: "What's one gate you'll definitely implement?"
- Look for: Understanding of why gates matter, practical thinking

**After Governance section:**
- Poll: "Which policy is most important for your organization?"
- Look for: Thoughtful consideration of their context

**After Risk section:**
- Ask: "What's your biggest vendor risk?"
- Look for: Specific risks, not generic concerns

**During roadmap exercise:**
- Observe realistic pacing and phasing
- Note whether plans connect to previous learning
- Listen for concerns about feasibility

### Summative Assessment (Homework)

**AI Adoption Plan Assessment**

**Current State Assessment (20%):**
- Accurate understanding of tool and team readiness
- Realistic assessment of governance maturity
- Clear articulation of starting point

**Governance Framework (20%):**
- Policies address key risk areas
- Appropriately tailored to organization
- Clear implementation path

**Strategic Roadmap (30%):**
- Realistic phasing over 18 months
- Clear goals and success metrics
- Appropriate pace (not too fast or slow)
- Connects to tool, people, and governance from Days 1-2

**Risk Management (15%):**
- Identifies real, organization-specific risks
- Mitigation strategies are practical
- Contingency planning evident

**Action Plan (15%):**
- First 90 days are concrete and specific
- Clear ownership and accountability
- Realistic with available resources

### Participant Feedback

**Track:**
- Engagement in exercises
- Quality of group work
- Questions and insights
- Participation in presentations

**Provide:**
- Real-time coaching and feedback
- Validation of thoughtful planning
- Encouragement for first steps
- Celebration of learning

### Post-Workshop Survey

**Key questions:**
- "How prepared do you feel to lead AI adoption?" (1-5 scale)
- "What's one specific action you'll take in the next week?"
- "What aspect of the workshop was most valuable?"
- "What would have been helpful to explore more?"
- "How has your thinking about AI adoption changed?"

---

## Teaching Resources

### Key Talking Points

**On Governance:**
- "Governance enables innovation; it doesn't inhibit it."
- "Good policies protect your team and your customers."
- "Policies should evolve as you learn."

**On Strategy:**
- "Tool adoption is just the beginning."
- "Competitive advantage comes from execution, not tools."
- "Long-term thinking beats short-term reactions."

**On Implementation:**
- "Start small and learn fast."
- "Pacing matters—don't rush or delay."
- "Getting started is the hardest part."

**On Risk:**
- "Plan for what could go wrong."
- "Vendors fail; have alternatives."
- "Security isn't negotiable."

### Common Q&A with Suggested Answers

**Q: "Do we really need policies if we're a small team?"**
A: "Start simple with 3-4 core policies, but writing them down makes a difference. As you grow, these become your foundation. Better to start early."

**Q: "What if the vendor we choose goes under?"**
A: "That's why you assess vendor stability early and have alternatives identified. Include transition support in contracts. It happens; plan for it."

**Q: "How do we balance innovation with security?"**
A: "Good governance actually enables both. Security shouldn't mean 'no AI tools'—it means 'use tools safely.' Define what's allowed and help teams use it well."

**Q: "Can we implement this faster than the roadmap?"**
A: "You can try, but usually speed creates problems. The roadmap is designed to let you learn at each phase. Rushing often means more problems later. Better to go steady."

**Q: "What if executives want immediate results?"**
A: "Show them the roadmap and explain the risks of rushing. Quick wins in months 1-3, but real value comes from sustainable adoption. Emphasize that your approach de-risks the investment."

**Q: "How do we know if this is working?"**
A: "That's what success metrics are for. Define them upfront, measure them regularly, and share results. Data drives better decisions than opinions."

### Presentation Slide Suggestions

**Slide Deck Topics:**
1. Three Days Recap: Tools → People → Organization
2. Quality Gates Framework (5 gates)
3. AI Code Governance Policies (8 policy areas)
4. Governance Policy Examples (show 2-3 samples)
5. Vendor Risk Assessment (5 risk categories)
6. Security Considerations Checklist
7. Competitive Advantage Levels (Levels 1-4)
8. Advantage Sources (Domain, Technical, Team, Data)
9. 18-Month Roadmap Template (4 phases)
10. Phase Details (Goals, Tools, Training, Metrics per phase)
11. Implementation Planning (Ownership, Timeline, Budget)
12. First 90 Days Action Plan
13. Final Thoughts: You've Got This!

### Pre-Session Checklist

- [ ] Review Days 1-2 homework submissions and assessment results
- [ ] Prepare case studies of governance successes and failures
- [ ] Gather real examples of policies and governance frameworks
- [ ] Test any videos or case study materials
- [ ] Print all templates and worksheets
- [ ] Prepare vendor risk examples
- [ ] Practice presenting quality gates framework
- [ ] Set up large wall space for roadmap exercise
- [ ] Have legal/compliance resources accessible
- [ ] Prepare sample roadmaps for reference
- [ ] Brief any co-instructors on Day 3 flow
- [ ] Set up materials for group exercises

---

## Closing Thoughts

Day 3 is about turning learning into action. Participants leave with concrete plans, realistic timelines, and organizational structures to support AI adoption. Your role is to provide frameworks, validate thinking, and encourage action.

The transition from Days 1-2 (tools and people) to Day 3 (organization and strategy) is intentional. By now, participants understand what they're adopting and how to support their teams. Today they learn how to make it sustainable and strategic.

**Key messages for closing:**

"You've spent three days learning frameworks, tools, and strategies. Now comes the hard part: implementation. But you're not starting from scratch. You have:

- Day 1: Clear criteria for tool evaluation
- Day 2: Understanding of your team and how to support them
- Day 3: Governance, strategy, and concrete plans

Your first 30 days matter. Choose one action. Tell your team. Make it real. Then build from there.

AI adoption isn't a project; it's a journey. You have what you need to lead it."

**Remember:**
- Governance enables innovation
- People drive success
- Strategy guides decisions
- Learning happens through doing
- You don't have to be perfect to start

Good luck. We're excited to see what you build.

---

**End of Day 3 Teacher's Guide**